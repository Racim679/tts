{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93GFgKEWM0tF"
   },
   "source": [
    "# \ud83c\udfa4 Fine-Tuning StyleTTS2 pour le Darija\n",
    "\n",
    "## Version Optimis\u00e9e GitHub + HuggingFace (Setup rapide ~3 min)\n",
    "\n",
    "**Sources:**\n",
    "- \ud83d\udce6 **Code:** `github.com/VOTRE-USERNAME/arable-tts` \u2b05\ufe0f Remplacez par votre username GitHub\n",
    "- \ud83c\udfb5 **Audio:** `huggingface.co/datasets/VOTRE-USERNAME/darija-dataset` \u2b05\ufe0f Remplacez par votre repo HF\n",
    "\n",
    "### Pr\u00e9requis:\n",
    "- GPU: T4, V100, ou A100 (minimum 16GB VRAM)\n",
    "- Dataset d\u00e9j\u00e0 upload\u00e9 sur Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TorA2qajM0tI"
   },
   "source": [
    "## \ud83d\udcdd Configuration - MODIFIEZ ICI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Udl9J2kXM0tI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764262464057,
     "user_tz": -60,
     "elapsed": 9,
     "user": {
      "displayName": "Racim Si Smail",
      "userId": "13880419371013186198"
     }
    },
    "outputId": "d6d1fc3e-249c-48a8-b0af-fa9f71740677"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 GitHub: Racim679/tts\n",
      "\u2705 HuggingFace: RacimPoly6/darija-tts-dataset\n"
     ]
    }
   ],
   "source": [
    "# \ud83d\udd27 CONFIGURATION - Modifiez ces valeurs\n",
    "GITHUB_REPO = \"Racim679/tts\"  # Votre repo GitHub\n",
    "\n",
    "print(f\"\u2705 GitHub: {GITHUB_REPO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X38KZ0oPM0tJ"
   },
   "source": [
    "## 1. V\u00e9rification GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHDX3MCgM0tJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764262472108,
     "user_tz": -60,
     "elapsed": 4931,
     "user": {
      "displayName": "Racim Si Smail",
      "userId": "13880419371013186198"
     }
    },
    "outputId": "1559dbbf-7bfb-43ee-8f03-8ca40714ed1b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Thu Nov 27 16:54:29 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   41C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "PyTorch: 2.9.0+cu126\n",
      "CUDA: True\n",
      "GPU: Tesla T4\n",
      "VRAM: 15.83 GB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrvdXR_dM0tJ"
   },
   "source": [
    "## 2. Installation des d\u00e9pendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIH2yS4sM0tJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764262539437,
     "user_tz": -60,
     "elapsed": 67327,
     "user": {
      "displayName": "Racim Si Smail",
      "userId": "13880419371013186198"
     }
    },
    "outputId": "7b1232b7-9e93-4386-e962-290c070eb221"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[?25l     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/180.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m60.7/60.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m213.4/213.4 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m569.0/569.0 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for monotonic_align (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Selecting previously unselected package libpcaudio0:amd64.\n",
      "(Reading database ... 121713 files and directories currently installed.)\n",
      "Preparing to unpack .../libpcaudio0_1.1-6build2_amd64.deb ...\n",
      "Unpacking libpcaudio0:amd64 (1.1-6build2) ...\n",
      "Selecting previously unselected package libsonic0:amd64.\n",
      "Preparing to unpack .../libsonic0_0.2.0-11build1_amd64.deb ...\n",
      "Unpacking libsonic0:amd64 (0.2.0-11build1) ...\n",
      "Selecting previously unselected package espeak-ng-data:amd64.\n",
      "Preparing to unpack .../espeak-ng-data_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
      "Unpacking espeak-ng-data:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
      "Selecting previously unselected package libespeak-ng1:amd64.\n",
      "Preparing to unpack .../libespeak-ng1_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
      "Unpacking libespeak-ng1:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
      "Selecting previously unselected package espeak-ng.\n",
      "Preparing to unpack .../espeak-ng_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
      "Unpacking espeak-ng (1.50+dfsg-10ubuntu0.1) ...\n",
      "Setting up libpcaudio0:amd64 (1.1-6build2) ...\n",
      "Setting up libsonic0:amd64 (0.2.0-11build1) ...\n",
      "Setting up espeak-ng-data:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
      "Setting up libespeak-ng1:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
      "Setting up espeak-ng (1.50+dfsg-10ubuntu0.1) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "\u2705 D\u00e9pendances install\u00e9es!\n"
     ]
    }
   ],
   "source": [
    "!pip install -q phonemizer==3.2.1 munch accelerate pydub nltk g2p_en num2words inflect unidecode pyyaml librosa scipy matplotlib soundfile\n",
    "!pip install -q torch torchaudio transformers einops einops-exts tqdm omegaconf huggingface_hub\n",
    "!pip install -q git+https://github.com/resemble-ai/monotonic_align.git\n",
    "!apt-get install -qq espeak-ng\n",
    "print(\"\u2705 D\u00e9pendances install\u00e9es!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_62eyJoM0tK"
   },
   "source": [
    "## 3. T\u00e9l\u00e9chargement du code (GitHub) et audio (HuggingFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tweWK8jQM0tK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764262899419,
     "user_tz": -60,
     "elapsed": 189,
     "user": {
      "displayName": "Racim Si Smail",
      "userId": "13880419371013186198"
     }
    },
    "outputId": "2d8d5314-71a4-4f00-e242-981da90f3be0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Returning existing local_dir `/content/dataset_darija` as remote repo cannot be accessed in `snapshot_download` (429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/RacimPoly6/darija-tts-dataset/revision/main (Request ID: Root=1-692883f6-71e7c9f42d7bdedc6a11c0b7;982b59e6-7e8d-4334-8b59-537dc900bfe9)\n",
      "\n",
      "We had to rate limit you, you hit the quota of 1000 api requests per 5 minutes period. Upgrade to a PRO user or Team/Enterprise organization account (https://hf.co/pricing) to get higher limits. See https://huggingface.co/docs/hub/rate-limits).\n",
      "WARNING:huggingface_hub._snapshot_download:Returning existing local_dir `/content/dataset_darija` as remote repo cannot be accessed in `snapshot_download` (429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/RacimPoly6/darija-tts-dataset/revision/main (Request ID: Root=1-692883f6-71e7c9f42d7bdedc6a11c0b7;982b59e6-7e8d-4334-8b59-537dc900bfe9)\n",
      "\n",
      "We had to rate limit you, you hit the quota of 1000 api requests per 5 minutes period. Upgrade to a PRO user or Team/Enterprise organization account (https://hf.co/pricing) to get higher limits. See https://huggingface.co/docs/hub/rate-limits).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2139\ufe0f StyleTTS2 d\u00e9j\u00e0 pr\u00e9sent\n",
      "\u2139\ufe0f Repo d\u00e9j\u00e0 pr\u00e9sent\n",
      "\ud83d\udce5 T\u00e9l\u00e9chargement audio depuis HuggingFace: RacimPoly6/darija-tts-dataset...\n",
      "\u2705 Dataset audio t\u00e9l\u00e9charg\u00e9!\n",
      "\ud83c\udfb5 1483 fichiers audio d\u00e9tect\u00e9s\n",
      "\ud83d\udcc4 metadata_train.csv pr\u00e9sent\n",
      "\ud83d\udcc4 metadata_eval.csv pr\u00e9sent\n",
      "\ud83d\udcc4 metadata.json pr\u00e9sent\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "# Monter Google Drive si n\u00e9cessaire\n",
    "if not os.path.exists('/content/drive'):\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "# Cloner StyleTTS2\n",
    "if not os.path.exists(\"/content/StyleTTS2\"):\n",
    "    !git clone https://github.com/yl4579/StyleTTS2.git /content/StyleTTS2\n",
    "    print(\"\u2705 StyleTTS2 clon\u00e9!\")\n",
    "else:\n",
    "    print(\"\u2139\ufe0f StyleTTS2 d\u00e9j\u00e0 pr\u00e9sent\")\n",
    "\n",
    "# Cloner votre repo avec les configs\n",
    "if not os.path.exists(\"/content/arable-tts\"):\n",
    "    !git clone https://github.com/{GITHUB_REPO}.git /content/arable-tts\n",
    "    print(\"\u2705 Configs clon\u00e9es depuis GitHub!\")\n",
    "else:\n",
    "    print(\"\u2139\ufe0f Repo d\u00e9j\u00e0 pr\u00e9sent\")\n",
    "\n",
    "# \ud83d\udce5 LOGIQUE DE T\u00c9L\u00c9CHARGEMENT DES DONN\u00c9ES\n",
    "# 1. V\u00e9rifier si le ZIP existe sur Drive\n",
    "drive_zip_path = \"/content/drive/MyDrive/darija_dataset.zip\"\n",
    "local_dataset_path = \"/content/dataset_darija\"\n",
    "\n",
    "if os.path.exists(drive_zip_path):\n",
    "    print(f\"\ud83d\udce6 ZIP trouv\u00e9 sur Drive: {drive_zip_path}\")\n",
    "    print(\"\u23f3 Extraction en cours... (\u00e7a peut prendre 1-2 min)\")\n",
    "    !unzip -q {drive_zip_path} -d {local_dataset_path}\n",
    "    print(\"\u2705 Donn\u00e9es extraites depuis Drive!\")\n",
    "else:\n",
    "    print(\"\u274c ZIP non trouv\u00e9 sur Drive! (darija_dataset.zip)\")\n",
    "    print(\"\u26a0\ufe0f Veuillez uploader le fichier zip \u00e0 la racine de votre Drive.\")\n",
    "\n",
    "# V\u00e9rifier ce qui a \u00e9t\u00e9 t\u00e9l\u00e9charg\u00e9\n",
    "if os.path.exists(f\"{local_dataset_path}/wavs\"):\n",
    "    wav_count = len([f for f in os.listdir(f\"{local_dataset_path}/wavs\") if f.endswith('.wav')])\n",
    "    print(f\"\ud83c\udfb5 {wav_count} fichiers audio d\u00e9tect\u00e9s\")\n",
    "\n",
    "metadata_files = [\"metadata_train.csv\", \"metadata_eval.csv\", \"metadata.json\"]\n",
    "for mf in metadata_files:\n",
    "    if os.path.exists(f\"{local_dataset_path}/{mf}\"):\n",
    "        print(f\"\ud83d\udcc4 {mf} pr\u00e9sent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udcc2 COPY OPTIMIZED FILES FROM YOUR REPO TO STYLETTS2\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "print(\"\ud83d\udd04 Mise \u00e0 jour des fichiers avec la version A100...\")\n",
    "\n",
    "# Copy optimized training script\n",
    "shutil.copy(\"/content/arable-tts/train_finetune.py\", \"/content/StyleTTS2/train_finetune.py\")\n",
    "print(\"\u2705 Script d'entra\u00eenement mis \u00e0 jour (AMP + TF32)\")\n",
    "\n",
    "# Copy A100 config\n",
    "os.makedirs(\"/content/StyleTTS2/Configs\", exist_ok=True)\n",
    "shutil.copy(\"/content/arable-tts/config_darija_a100.yml\", \"/content/StyleTTS2/Configs/config_darija_a100.yml\")\n",
    "print(\"\u2705 Config A100 copi\u00e9e\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFiHnpkdM0tK"
   },
   "source": [
    "## 4. T\u00e9l\u00e9chargement des mod\u00e8les pr\u00e9-entra\u00een\u00e9s"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "minimal_config = \"\"\"log_dir: \".\"\n",
    "save_freq: 1\n",
    "device: \"cuda\"\n",
    "epochs_1st: 200\n",
    "epochs_2nd: 800\n",
    "batch_size: 16\n",
    "max_len: 200\n",
    "\n",
    "model_params:\n",
    "  n_token: 178\n",
    "\n",
    "F0_path: \"Utils/JDC/bst.t7\"\n",
    "ASR_config: \"Utils/ASR/config.yml\"\n",
    "ASR_path: \"Utils/ASR/epoch_00080.pth\"\n",
    "\"\"\"\n",
    "\n",
    "with open('/content/StyleTTS2/Utils/ASR/config.yml', 'w') as f:\n",
    "    f.write(minimal_config)\n",
    "\n",
    "print(\"\u2705 Config ASR cr\u00e9\u00e9\")\n",
    "\n",
    "# V\u00e9rifier\n",
    "with open('/content/StyleTTS2/Utils/ASR/config.yml', 'r') as f:\n",
    "    print(f.read())\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O6JSdiOhTd7P",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764263697654,
     "user_tz": -60,
     "elapsed": 36,
     "user": {
      "displayName": "Racim Si Smail",
      "userId": "13880419371013186198"
     }
    },
    "outputId": "ef780f6a-0c15-40dc-8a73-27a145a85d58"
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Config ASR cr\u00e9\u00e9\n",
      "log_dir: \".\"\n",
      "save_freq: 1\n",
      "device: \"cuda\"\n",
      "epochs_1st: 200\n",
      "epochs_2nd: 800\n",
      "batch_size: 16\n",
      "max_len: 200\n",
      "\n",
      "model_params:\n",
      "  n_token: 178\n",
      "\n",
      "F0_path: \"Utils/JDC/bst.t7\"\n",
      "ASR_config: \"Utils/ASR/config.yml\"\n",
      "ASR_path: \"Utils/ASR/epoch_00080.pth\"\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# V\u00e9rifier que les fichiers de config existent et sont valides\n",
    "asr_config_path = \"/content/StyleTTS2/Utils/ASR/config.yml\"\n",
    "if os.path.exists(asr_config_path):\n",
    "    with open(asr_config_path, 'r') as f:\n",
    "        content = f.read()\n",
    "        if len(content) > 0:\n",
    "             print(f\"\u2705 ASR config OK ({len(content)} bytes)\")\n",
    "        else:\n",
    "             print(\"\u274c ASR config est vide!\")\n",
    "else:\n",
    "      print(\"\u274c ASR config n'existe pas!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q7K445rmR41m",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764263769374,
     "user_tz": -60,
     "elapsed": 22,
     "user": {
      "displayName": "Racim Si Smail",
      "userId": "13880419371013186198"
     }
    },
    "outputId": "35f3436d-0112-4958-d167-624455717456"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 ASR config OK (233 bytes)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "3x8qrRc1Sch5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1tg2NNUM0tL"
   },
   "source": [
    "## 5. Patches PyTorch 2.6+ (CRITIQUE!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Etn23G6nM0tL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764263773439,
     "user_tz": -60,
     "elapsed": 6,
     "user": {
      "displayName": "Racim Si Smail",
      "userId": "13880419371013186198"
     }
    },
    "outputId": "2762da94-2f85-4d7d-a249-3ec8ea762bd8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2139\ufe0f OK: models.py\n",
      "\u2139\ufe0f OK: models.py\n",
      "\u2139\ufe0f OK: model.py\n",
      "\u2139\ufe0f OK: util.py\n",
      "\u2139\ufe0f OK: meldataset.py\n",
      "\n",
      "\u2705 Patches PyTorch appliqu\u00e9s!\n"
     ]
    }
   ],
   "source": [
    "import re, os\n",
    "\n",
    "files_to_patch = [\n",
    "    \"/content/StyleTTS2/models.py\",\n",
    "    \"/content/StyleTTS2/Utils/ASR/models.py\",\n",
    "    \"/content/StyleTTS2/Utils/JDC/model.py\",\n",
    "    \"/content/StyleTTS2/Utils/PLBERT/util.py\",\n",
    "    \"/content/StyleTTS2/meldataset.py\",\n",
    "]\n",
    "\n",
    "for filepath in files_to_patch:\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            content = f.read()\n",
    "        if 'torch.load' in content and 'weights_only' not in content:\n",
    "            new_content = re.sub(r'torch\\.load\\(([^)]+)\\)', r'torch.load(\\1, weights_only=False)', content)\n",
    "            with open(filepath, 'w') as f:\n",
    "                f.write(new_content)\n",
    "            print(f\"\u2705 Patched: {os.path.basename(filepath)}\")\n",
    "        else:\n",
    "            print(f\"\u2139\ufe0f OK: {os.path.basename(filepath)}\")\n",
    "\n",
    "print(\"\\n\u2705 Patches PyTorch appliqu\u00e9s!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyVaEZ-AM0tL"
   },
   "source": [
    "## 6. Pr\u00e9paration des donn\u00e9es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PioG1rvKM0tL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764263783666,
     "user_tz": -60,
     "elapsed": 7422,
     "user": {
      "displayName": "Racim Si Smail",
      "userId": "13880419371013186198"
     }
    },
    "outputId": "ba73389c-6b95-4010-8444-c2a6dad5b54c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83c\udfb5 Copie des fichiers audio...\n",
      "\u2705 1483 fichiers audio copi\u00e9s\n",
      "\u2705 Train: 1442 samples\n",
      "\u2705 Val: 76 samples\n"
     ]
    }
   ],
   "source": [
    "import json, random, os, shutil\n",
    "\n",
    "os.makedirs(\"/content/StyleTTS2/Data\", exist_ok=True)\n",
    "os.makedirs(\"/content/StyleTTS2/wavs\", exist_ok=True)\n",
    "\n",
    "# Copier les fichiers audio\n",
    "print(\"\ud83c\udfb5 Copie des fichiers audio...\")\n",
    "source_wavs = \"/content/dataset_darija/wavs\"\n",
    "dest_wavs = \"/content/StyleTTS2/wavs\"\n",
    "\n",
    "if os.path.exists(source_wavs):\n",
    "    for f in os.listdir(source_wavs):\n",
    "        if f.endswith('.wav'):\n",
    "            shutil.copy(f\"{source_wavs}/{f}\", f\"{dest_wavs}/{f}\")\n",
    "    print(f\"\u2705 {len(os.listdir(dest_wavs))} fichiers audio copi\u00e9s\")\n",
    "else:\n",
    "    print(\"\u274c Dossier wavs introuvable!\")\n",
    "\n",
    "# Cr\u00e9er train/val lists depuis metadata.json\n",
    "metadata_path = \"/content/dataset_darija/metadata.json\"\n",
    "if os.path.exists(metadata_path):\n",
    "    with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    random.seed(42)\n",
    "    random.shuffle(metadata)\n",
    "    split = int(len(metadata) * 0.95)\n",
    "    train_data, eval_data = metadata[:split], metadata[split:]\n",
    "\n",
    "    with open('/content/StyleTTS2/Data/train_list.txt', 'w', encoding='utf-8') as f:\n",
    "        for item in train_data:\n",
    "            f.write(f\"{item['audio_file']}|{item['text'].replace(chr(10), ' ')}|0\\n\")\n",
    "\n",
    "    with open('/content/StyleTTS2/Data/val_list.txt', 'w', encoding='utf-8') as f:\n",
    "        for item in eval_data:\n",
    "            f.write(f\"{item['audio_file']}|{item['text'].replace(chr(10), ' ')}|0\\n\")\n",
    "\n",
    "    print(f\"\u2705 Train: {len(train_data)} samples\")\n",
    "    print(f\"\u2705 Val: {len(eval_data)} samples\")\n",
    "else:\n",
    "    print(\"\u274c metadata.json introuvable!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "syQyWnejM0tL"
   },
   "source": [
    "## 7. Configuration du training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oufoaImkM0tL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764263783686,
     "user_tz": -60,
     "elapsed": 5,
     "user": {
      "displayName": "Racim Si Smail",
      "userId": "13880419371013186198"
     }
    },
    "outputId": "c75d1978-0263-4c45-bbd8-f5e076d20527"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Configuration cr\u00e9\u00e9e!\n"
     ]
    }
   ],
   "source": [
    "import yaml, os\n",
    "\n",
    "config = {\n",
    "    'log_dir': 'Models/Darija',\n",
    "    'save_freq': 10,\n",
    "    'device': 'cuda',\n",
    "    'epochs_1st': 0,\n",
    "    'epochs_2nd': 80,\n",
    "    'batch_size': 32,\n",
    "    'max_len': 400,\n",
    "    'pretrained_model': 'Models/LibriTTS/epochs_2nd_00020.pth',\n",
    "    'data_params': {\n",
    "        'train_data': 'Data/train_list.txt',\n        'num_workers': 8,\n",
    "        'val_data': 'Data/val_list.txt',\n",
    "        'root_path': '',\n",
    "        'OOD_data': 'Data/OOD_texts.txt',\n",
    "        'min_length': 50,\n",
    "        'sample_rate': 24000,\n",
    "    },\n",
    "    'preprocess_params': {\n",
    "        'sr': 24000,\n",
    "        'spect_params': {\n",
    "            'n_fft': 2048,\n",
    "            'win_length': 1200,\n",
    "            'hop_length': 300,\n",
    "            'n_mels': 80\n",
    "        }\n",
    "    },\n",
    "    'model_params': {\n",
    "        'multispeaker': False,\n",
    "        'dim_in': 64,\n",
    "        'hidden_dim': 512,\n",
    "        'max_conv_dim': 512,\n",
    "        'n_layer': 3,\n",
    "        'n_mels': 80,\n",
    "        'n_token': 178,\n",
    "        'max_dur': 50,\n",
    "        'style_dim': 128,\n",
    "        'dropout': 0.2,\n",
    "        'decoder': {\n",
    "            'type': 'istftnet',\n",
    "            'resblock_kernel_sizes': [3, 7, 11],\n",
    "            'upsample_rates': [10, 6],\n",
    "            'upsample_initial_channel': 512,\n",
    "            'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]],\n",
    "            'upsample_kernel_sizes': [20, 12],\n",
    "            'gen_istft_n_fft': 20,\n",
    "            'gen_istft_hop_size': 5\n",
    "        },\n",
    "        'slm': {\n",
    "            'model': 'microsoft/wavlm-base-plus',\n",
    "            'sr': 16000,\n",
    "            'hidden': 768,\n",
    "            'nlayers': 13,\n",
    "            'initial_channel': 64\n",
    "        },\n",
    "        'diffusion': {\n",
    "            'embedding_mask_proba': 0.1,\n",
    "            'transformer': {\n",
    "                'num_layers': 3,\n",
    "                'num_heads': 8,\n",
    "                'head_features': 64,\n",
    "                'multiplier': 2\n",
    "            },\n",
    "            'dist': {\n",
    "                'sigma_data': 0.2,\n",
    "                'estimate_sigma_data': True,\n",
    "                'mean': -3.0,\n",
    "                'std': 1.0\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'loss_params': {\n",
    "        'lambda_mel': 5.0,\n",
    "        'lambda_gen': 1.0,\n",
    "        'lambda_slm': 1.0,\n",
    "        'lambda_mono': 1.0,\n",
    "        'lambda_s2s': 1.0,\n",
    "        'lambda_F0': 1.0,\n",
    "        'lambda_norm': 1.0,\n",
    "        'lambda_dur': 1.0,\n",
    "        'lambda_ce': 20.0,\n",
    "        'lambda_sty': 1.0,\n",
    "        'lambda_diff': 1.0,\n",
    "        'diff_epoch': 20,\n",
    "        'joint_epoch': 40\n",
    "    },\n",
    "    'optimizer_params': {'lr': 0.0001},\n",
    "    'slmadv_params': {\n",
    "        'min_len': 400,\n",
    "        'max_len': 500,\n",
    "        'batch_percentage': 0.5,\n",
    "        'iter': 10,\n",
    "        'thresh': 5.0,\n",
    "        'scale': 0.01,\n",
    "        'sig': 1.5\n",
    "    },\n",
    "    'F0_path': 'Utils/JDC/bst.t7',\n",
    "    'ASR_config': 'Utils/ASR/config.yml',\n",
    "    'ASR_path': 'Utils/ASR/epoch_00080.pth',\n",
    "    'PLBERT_dir': 'Utils/PLBERT/',\n",
    "}\n",
    "\n",
    "os.makedirs('/content/StyleTTS2/Configs', exist_ok=True)\n",
    "with open('/content/StyleTTS2/Configs/config_darija_a100.yml', 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(\"\u2705 Configuration cr\u00e9\u00e9e!\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "  import requests\n",
    "  import os\n",
    "  import time\n",
    "\n",
    "  print(\"\ud83d\udce5 T\u00e9l\u00e9chargement depuis les VRAIS liens StyleTTS2...\\n\")\n",
    "\n",
    "  downloads = [\n",
    "      (\"JDC\", \"https://github.com/yl4579/StyleTTS2/raw/main/Utils/JDC/bst.t7\",\n",
    "  \"/content/StyleTTS2/Utils/JDC/bst.t7\"),\n",
    "      (\"ASR model\", \"https://github.com/yl4579/StyleTTS2/raw/main/Utils/ASR/epoch_00080.pth\",\n",
    "  \"/content/StyleTTS2/Utils/ASR/epoch_00080.pth\"),\n",
    "      (\"PLBERT\", \"https://github.com/yl4579/StyleTTS2/raw/main/Utils/PLBERT/step_1000000.t7\",\n",
    "  \"/content/StyleTTS2/Utils/PLBERT/step_1000000.t7\"),\n",
    "      (\"PLBERT config\", \"https://github.com/yl4579/StyleTTS2/raw/main/Utils/PLBERT/config.yml\",\n",
    "  \"/content/StyleTTS2/Utils/PLBERT/config.yml\"),\n",
    "  ]\n",
    "\n",
    "  for name, url, path in downloads:\n",
    "      print(f\"\ud83d\udce5 {name}...\")\n",
    "      try:\n",
    "          response = requests.get(url, stream=True, timeout=300, allow_redirects=True)\n",
    "          if response.status_code == 200:\n",
    "              with open(path, 'wb') as f:\n",
    "                  for chunk in response.iter_content(chunk_size=8192):\n",
    "                      f.write(chunk)\n",
    "\n",
    "              size = os.path.getsize(path) / 1024 / 1024\n",
    "              print(f\"\u2705 {size:.1f} MB\\n\")\n",
    "          else:\n",
    "              print(f\"\u274c HTTP {response.status_code}\\n\")\n",
    "      except Exception as e:\n",
    "          print(f\"\u274c {str(e)}\\n\")\n",
    "      time.sleep(2)\n",
    "\n",
    "  # V\u00e9rification finale\n",
    "  print(\"\\n\ud83d\udd0d V\u00e9rification:\")\n",
    "  for name, _, path in downloads:\n",
    "      if os.path.exists(path) and os.path.getsize(path) > 0:\n",
    "          print(f\"\u2705 {name}: OK\")\n",
    "      else:\n",
    "          print(f\"\u274c {name}: MANQUANT\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aw36TE_oU7pD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764264126602,
     "user_tz": -60,
     "elapsed": 14777,
     "user": {
      "displayName": "Racim Si Smail",
      "userId": "13880419371013186198"
     }
    },
    "outputId": "d1781f26-894b-4eb6-ae7c-0d886093f76b"
   },
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udce5 T\u00e9l\u00e9chargement depuis les VRAIS liens StyleTTS2...\n",
      "\n",
      "\ud83d\udce5 JDC...\n",
      "\u2705 20.1 MB\n",
      "\n",
      "\ud83d\udce5 ASR model...\n",
      "\u2705 90.2 MB\n",
      "\n",
      "\ud83d\udce5 PLBERT...\n",
      "\u2705 24.0 MB\n",
      "\n",
      "\ud83d\udce5 PLBERT config...\n",
      "\u2705 0.0 MB\n",
      "\n",
      "\n",
      "\ud83d\udd0d V\u00e9rification:\n",
      "\u2705 JDC: OK\n",
      "\u2705 ASR model: OK\n",
      "\u2705 PLBERT: OK\n",
      "\u2705 PLBERT config: OK\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8760Rp4M0tM"
   },
   "source": [
    "## 8. V\u00e9rification finale avant training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0uJOShB1M0tM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764264134286,
     "user_tz": -60,
     "elapsed": 14,
     "user": {
      "displayName": "Racim Si Smail",
      "userId": "13880419371013186198"
     }
    },
    "outputId": "2979a2d1-a7c1-433b-dab6-fdba6a6076d4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Config\n",
      "\u2705 Audio (wavs)\n",
      "\u2705 Train list\n",
      "\u2705 Val list\n",
      "\u2705 Mod\u00e8le LibriTTS\n",
      "\u2705 JDC\n",
      "\u2705 ASR\n",
      "\u2705 PLBERT\n",
      "\n",
      "\ud83c\udfb5 1483 fichiers audio pr\u00eats\n",
      "\n",
      "\ud83c\udf89 TOUT EST PR\u00caT! Vous pouvez lancer le training!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "checks = {\n",
    "    \"Config\": \"/content/StyleTTS2/Configs/config_darija_ft.yml\",\n",
    "    \"Audio (wavs)\": \"/content/StyleTTS2/wavs\",\n",
    "    \"Train list\": \"/content/StyleTTS2/Data/train_list.txt\",\n",
    "    \"Val list\": \"/content/StyleTTS2/Data/val_list.txt\",\n",
    "    \"Mod\u00e8le LibriTTS\": \"/content/StyleTTS2/Models/LibriTTS/epochs_2nd_00020.pth\",\n",
    "    \"JDC\": \"/content/StyleTTS2/Utils/JDC/bst.t7\",\n",
    "    \"ASR\": \"/content/StyleTTS2/Utils/ASR/epoch_00080.pth\",\n",
    "    \"PLBERT\": \"/content/StyleTTS2/Utils/PLBERT/step_1000000.t7\",\n",
    "}\n",
    "\n",
    "all_ok = True\n",
    "for name, path in checks.items():\n",
    "    exists = os.path.exists(path)\n",
    "    status = \"\u2705\" if exists else \"\u274c\"\n",
    "    print(f\"{status} {name}\")\n",
    "    if not exists:\n",
    "        all_ok = False\n",
    "\n",
    "# Compter les fichiers\n",
    "if os.path.exists(\"/content/StyleTTS2/wavs\"):\n",
    "    wav_count = len([f for f in os.listdir(\"/content/StyleTTS2/wavs\") if f.endswith('.wav')])\n",
    "    print(f\"\\n\ud83c\udfb5 {wav_count} fichiers audio pr\u00eats\")\n",
    "\n",
    "if all_ok:\n",
    "    print(\"\\n\ud83c\udf89 TOUT EST PR\u00caT! Vous pouvez lancer le training!\")\n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f Certains fichiers manquent. V\u00e9rifiez les \u00e9tapes pr\u00e9c\u00e9dentes.\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# V\u00e9rifier que tous les fichiers critiques existent\n",
    "import os\n",
    "\n",
    "files_to_check = {\n",
    "    \"Config principal\": \"/content/StyleTTS2/Configs/config_darija_ft.yml\",\n",
    "    \"Train list\": \"/content/StyleTTS2/Data/train_list.txt\",\n",
    "    \"Val list\": \"/content/StyleTTS2/Data/val_list.txt\",\n",
    "    \"Mod\u00e8le pretrained\": \"/content/StyleTTS2/Models/LibriTTS/epochs_2nd_00020.pth\",\n",
    "    \"JDC\": \"/content/StyleTTS2/Utils/JDC/bst.t7\",\n",
    "    \"ASR model\": \"/content/StyleTTS2/Utils/ASR/epoch_00080.pth\",\n",
    "    \"ASR config\": \"/content/StyleTTS2/Utils/ASR/config.yml\",\n",
    "    \"PLBERT\": \"/content/StyleTTS2/Utils/PLBERT/step_1000000.t7\",\n",
    "    \"PLBERT config\": \"/content/StyleTTS2/Utils/PLBERT/config.yml\"\n",
    "}\n",
    "\n",
    "print(\"\ud83d\udd0d V\u00e9rification des fichiers critiques:\\n\")\n",
    "all_ok = True\n",
    "\n",
    "for name, path in files_to_check.items():\n",
    "    exists = os.path.exists(path)\n",
    "    size = os.path.getsize(path) if exists else 0\n",
    "    status = \"\u2705\" if exists and size > 0 else \"\u274c\"\n",
    "\n",
    "    if exists and size > 0:\n",
    "        print(f\"{status} {name}: {size/1024/1024:.1f} MB\")\n",
    "    else:\n",
    "        print(f\"{status} {name}: VIDE ou MANQUANT\")\n",
    "\n",
    "    if not exists or size == 0:\n",
    "        all_ok = False\n",
    "\n",
    "print(f\"\\n{'\ud83c\udf89 Tout OK' if all_ok else '\u26a0\ufe0f Fichiers manquants d\u00e9tect\u00e9s'}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOuOsRpzUmRb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764264137280,
     "user_tz": -60,
     "elapsed": 95,
     "user": {
      "displayName": "Racim Si Smail",
      "userId": "13880419371013186198"
     }
    },
    "outputId": "ff09db25-f7ba-4cc6-f9ca-f2b8eee83386"
   },
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udd0d V\u00e9rification des fichiers critiques:\n",
      "\n",
      "\u2705 Config principal: 0.0 MB\n",
      "\u2705 Train list: 0.1 MB\n",
      "\u2705 Val list: 0.0 MB\n",
      "\u2705 Mod\u00e8le pretrained: 735.7 MB\n",
      "\u2705 JDC: 20.1 MB\n",
      "\u2705 ASR model: 90.2 MB\n",
      "\u2705 ASR config: 0.0 MB\n",
      "\u2705 PLBERT: 24.0 MB\n",
      "\u2705 PLBERT config: 0.0 MB\n",
      "\n",
      "\ud83c\udf89 Tout OK\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "asr_config_optimal = \"\"\"log_dir: \".\"\n",
    "save_freq: 5\n",
    "log_interval: 10\n",
    "\n",
    "epochs: 200\n",
    "batch_size: 16\n",
    "optimizer: \"AdamW\"\n",
    "\n",
    "data_params:\n",
    "  train_data: \"\"\n",
    "  val_data: \"\"\n",
    "  root_path: \"\"\n",
    "  OOD_data: \"\"\n",
    "  min_length: 50\n",
    "  max_length: 500\n",
    "\n",
    "loss_params:\n",
    "  lambda_mel: 5.0\n",
    "\n",
    "optimizer_params:\n",
    "  lr: 0.0001\n",
    "  betas: [0.9, 0.99]\n",
    "  weight_decay: 0.0\n",
    "\n",
    "model_params:\n",
    "  dim_in: 80\n",
    "  hidden_dim: 512\n",
    "  n_token: 178\n",
    "  token_embedding_dim: 512\n",
    "\n",
    "preprocess_params:\n",
    "  sr: 24000\n",
    "  spect_params:\n",
    "    n_fft: 2048\n",
    "    win_length: 1200\n",
    "    hop_length: 300\n",
    "    n_mels: 80\n",
    "\"\"\"\n",
    "\n",
    "# Sauvegarder\n",
    "with open('/content/StyleTTS2/Utils/ASR/config.yml', 'w') as f:\n",
    "    f.write(asr_config_optimal)\n",
    "\n",
    "print(\"\u2705 Config ASR optimal cr\u00e9\u00e9\\n\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# PLBERT CONFIG\n",
    "# -----------------------------------------------------\n",
    "\n",
    "plbert_config = \"\"\"log_dir: \".\"\n",
    "save_freq: 2\n",
    "log_interval: 10\n",
    "device: \"cuda\"\n",
    "epochs: 50\n",
    "batch_size: 256\n",
    "\n",
    "model_params:\n",
    "  model_type: \"bert-base-uncased\"\n",
    "  hidden_size: 768\n",
    "  num_hidden_layers: 12\n",
    "  num_attention_heads: 12\n",
    "\n",
    "data_params:\n",
    "  train_data: \"\"\n",
    "  val_data: \"\"\n",
    "\n",
    "optimizer_params:\n",
    "  lr: 0.0001\n",
    "\"\"\"\n",
    "\n",
    "with open('/content/StyleTTS2/Utils/PLBERT/config.yml', 'w') as f:\n",
    "    f.write(plbert_config)\n",
    "\n",
    "print(\"\u2705 Config PLBERT cr\u00e9\u00e9\\n\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# V\u00c9RIFICATION COMPL\u00c8TE\n",
    "# -----------------------------------------------------\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"\ud83d\udd0d V\u00c9RIFICATION FINALE COMPL\u00c8TE:\\n\")\n",
    "\n",
    "critical_files = {\n",
    "    \"Config Training\": \"/content/StyleTTS2/Configs/config_darija_ft.yml\",\n",
    "    \"Train List\": \"/content/StyleTTS2/Data/train_list.txt\",\n",
    "    \"Val List\": \"/content/StyleTTS2/Data/val_list.txt\",\n",
    "    \"Pretrained Model\": \"/content/StyleTTS2/Models/LibriTTS/epochs_2nd_00020.pth\",\n",
    "    \"LibriTTS Config\": \"/content/StyleTTS2/Models/LibriTTS/config.yml\",\n",
    "    \"JDC Model\": \"/content/StyleTTS2/Utils/JDC/bst.t7\",\n",
    "    \"ASR Model\": \"/content/StyleTTS2/Utils/ASR/epoch_00080.pth\",\n",
    "    \"ASR Config\": \"/content/StyleTTS2/Utils/ASR/config.yml\",\n",
    "    \"PLBERT Model\": \"/content/StyleTTS2/Utils/PLBERT/step_1000000.t7\",\n",
    "    \"PLBERT Config\": \"/content/StyleTTS2/Utils/PLBERT/config.yml\"\n",
    "}\n",
    "\n",
    "all_good = True\n",
    "\n",
    "for name, path in critical_files.items():\n",
    "    if os.path.exists(path):\n",
    "        size = os.path.getsize(path)\n",
    "        if size > 0:\n",
    "            size_mb = size / 1024 / 1024\n",
    "            print(f\"\u2705 {name}: {size_mb:.2f} MB\")\n",
    "        else:\n",
    "            print(f\"\u274c {name}: VIDE (0 bytes)\")\n",
    "            all_good = False\n",
    "    else:\n",
    "        print(f\"\u274c {name}: MANQUANT\")\n",
    "        all_good = False\n",
    "\n",
    "\n",
    "# Compter les fichiers audio\n",
    "wavs_dir = \"/content/StyleTTS2/wavs\"\n",
    "if os.path.exists(wavs_dir):\n",
    "    wav_files = [f for f in os.listdir(wavs_dir) if f.endswith('.wav')]\n",
    "    print(f\"\\n\ud83c\udfb5 Fichiers audio: {len(wav_files)} fichiers WAV\")\n",
    "else:\n",
    "    print(\"\\n\u274c Dossier wavs manquant!\")\n",
    "    all_good = False\n",
    "\n",
    "\n",
    "print(f\"\\n{'\ud83c\udf89 TOUT EST PR\u00caT POUR LE TRAINING!' if all_good else '\u26a0\ufe0f FICHIERS MANQUANTS - VOIR CI-DESSUS'}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9K9biZ8OXZIf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764264615362,
     "user_tz": -60,
     "elapsed": 105,
     "user": {
      "displayName": "Racim Si Smail",
      "userId": "13880419371013186198"
     }
    },
    "outputId": "40a9adf6-f5c9-43e4-cc0b-0b1b5730278d"
   },
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Config ASR optimal cr\u00e9\u00e9\n",
      "\n",
      "\u2705 Config PLBERT cr\u00e9\u00e9\n",
      "\n",
      "\ud83d\udd0d V\u00c9RIFICATION FINALE COMPL\u00c8TE:\n",
      "\n",
      "\u2705 Config Training: 0.00 MB\n",
      "\u2705 Train List: 0.10 MB\n",
      "\u2705 Val List: 0.01 MB\n",
      "\u2705 Pretrained Model: 735.66 MB\n",
      "\u2705 LibriTTS Config: 0.00 MB\n",
      "\u2705 JDC Model: 20.06 MB\n",
      "\u2705 ASR Model: 90.17 MB\n",
      "\u2705 ASR Config: 0.00 MB\n",
      "\u2705 PLBERT Model: 24.02 MB\n",
      "\u2705 PLBERT Config: 0.00 MB\n",
      "\n",
      "\ud83c\udfb5 Fichiers audio: 1483 fichiers WAV\n",
      "\n",
      "\ud83c\udf89 TOUT EST PR\u00caT POUR LE TRAINING!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3g8qaxeM0tM"
   },
   "source": [
    "## 9. \ud83d\ude80 Lancement du Fine-Tuning\n",
    "\n",
    "\u26a0\ufe0f **Dur\u00e9e estim\u00e9e: 8-12h sur GPU T4**\n",
    "\n",
    "Checkpoints sauvegard\u00e9s tous les 10 epochs dans `/content/StyleTTS2/Models/Darija/`"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "  # Cell: Create PLBERT config that matches checkpoint\n",
    "  import yaml\n",
    "  import os\n",
    "\n",
    "  plbert_config = {\n",
    "      'model_params': {\n",
    "          'vocab_size': 178,           # Must match checkpoint (not 30000)\n",
    "          'hidden_size': 768,\n",
    "          'num_hidden_layers': 12,\n",
    "          'num_attention_heads': 12,\n",
    "          'intermediate_size': 2048,   # Must match checkpoint (not 16384)\n",
    "          'hidden_act': 'gelu',\n",
    "          'hidden_dropout_prob': 0.0,\n",
    "          'attention_probs_dropout_prob': 0.0,\n",
    "          'max_position_embeddings': 512,\n",
    "          'type_vocab_size': 2,\n",
    "          'initializer_range': 0.02,\n",
    "          'layer_norm_eps': 1e-12\n",
    "      }\n",
    "  }\n",
    "\n",
    "  # Save PLBERT config\n",
    "  plbert_config_path = '/content/StyleTTS2/Utils/PLBERT/config.yml'\n",
    "  os.makedirs(os.path.dirname(plbert_config_path), exist_ok=True)\n",
    "\n",
    "  with open(plbert_config_path, 'w') as f:\n",
    "      yaml.dump(plbert_config, f, default_flow_style=False)\n",
    "\n",
    "  print(f\"\u2705 PLBERT config saved to {plbert_config_path}\")\n",
    "  print(\"\\nConfig:\")\n",
    "  with open(plbert_config_path, 'r') as f:\n",
    "      print(f.read())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uNpBVbcyYdJk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764265489890,
     "user_tz": -60,
     "elapsed": 66,
     "user": {
      "displayName": "Racim Si Smail",
      "userId": "13880419371013186198"
     }
    },
    "outputId": "0de7aae5-6b53-434c-d1a8-553b8a22730c"
   },
   "execution_count": 51,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 PLBERT config saved to /content/StyleTTS2/Utils/PLBERT/config.yml\n",
      "\n",
      "Config:\n",
      "model_params:\n",
      "  attention_probs_dropout_prob: 0.0\n",
      "  hidden_act: gelu\n",
      "  hidden_dropout_prob: 0.0\n",
      "  hidden_size: 768\n",
      "  initializer_range: 0.02\n",
      "  intermediate_size: 2048\n",
      "  layer_norm_eps: 1.0e-12\n",
      "  max_position_embeddings: 512\n",
      "  num_attention_heads: 12\n",
      "  num_hidden_layers: 12\n",
      "  type_vocab_size: 2\n",
      "  vocab_size: 178\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell: Check what's missing in config\n",
    "config_file = '/content/StyleTTS2/Configs/config_darija_ft.yml'\n",
    "\n",
    "with open(config_file, 'r') as f:\n",
    "    content = f.read()\n",
    "    print(\"Current config content:\")\n",
    "    print(content)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXA2N71ZbDlt",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764266252319,
     "user_tz": -60,
     "elapsed": 31,
     "user": {
      "displayName": "Racim Si Smail",
      "userId": "13880419371013186198"
     }
    },
    "outputId": "13981235-380b-461c-82e9-a96ecdf4bbbb"
   },
   "execution_count": 60,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current config content:\n",
      "ASR_config: Utils/ASR/config.yml\n",
      "ASR_path: Utils/ASR/epoch_00080.pth\n",
      "F0_path: Utils/JDC/bst.t7\n",
      "PLBERT_dir: Utils/PLBERT/\n",
      "batch_size: 4\n",
      "data_params:\n",
      "  OOD_data: Data/OOD_texts.txt\n",
      "  min_length: 50\n",
      "  root_path: ''\n",
      "  sample_rate: 24000\n",
      "  train_data: Data/train_list.txt\n",
      "  val_data: Data/val_list.txt\n",
      "device: cuda\n",
      "epochs_1st: 0\n",
      "epochs_2nd: 80\n",
      "log_dir: Models/Darija\n",
      "loss_params:\n",
      "  diff_epoch: 20\n",
      "  joint_epoch: 40\n",
      "  lambda_F0: 1.0\n",
      "  lambda_ce: 20.0\n",
      "  lambda_diff: 1.0\n",
      "  lambda_dur: 1.0\n",
      "  lambda_gen: 1.0\n",
      "  lambda_mel: 5.0\n",
      "  lambda_mono: 1.0\n",
      "  lambda_norm: 1.0\n",
      "  lambda_s2s: 1.0\n",
      "  lambda_slm: 1.0\n",
      "  lambda_sty: 1.0\n",
      "max_len: 400\n",
      "model_params:\n",
      "  decoder:\n",
      "    gen_istft_hop_size: 5\n",
      "    gen_istft_n_fft: 20\n",
      "    resblock_dilation_sizes:\n",
      "    - - 1\n",
      "      - 3\n",
      "      - 5\n",
      "    - - 1\n",
      "      - 3\n",
      "      - 5\n",
      "    - - 1\n",
      "      - 3\n",
      "      - 5\n",
      "    resblock_kernel_sizes:\n",
      "    - 3\n",
      "    - 7\n",
      "    - 11\n",
      "    type: istftnet\n",
      "    upsample_initial_channel: 512\n",
      "    upsample_kernel_sizes:\n",
      "    - 20\n",
      "    - 12\n",
      "    upsample_rates:\n",
      "    - 10\n",
      "    - 6\n",
      "  diffusion:\n",
      "    dist:\n",
      "      estimate_sigma_data: true\n",
      "      mean: -3.0\n",
      "      sigma_data: 0.2\n",
      "      std: 1.0\n",
      "    embedding_mask_proba: 0.1\n",
      "    transformer:\n",
      "      head_features: 64\n",
      "      multiplier: 2\n",
      "      num_heads: 8\n",
      "      num_layers: 3\n",
      "  dim_in: 64\n",
      "  dropout: 0.2\n",
      "  hidden_dim: 512\n",
      "  max_conv_dim: 512\n",
      "  max_dur: 50\n",
      "  multispeaker: false\n",
      "  n_layer: 3\n",
      "  n_mels: 80\n",
      "  n_token: 178\n",
      "  slm:\n",
      "    hidden: 768\n",
      "    initial_channel: 64\n",
      "    model: microsoft/wavlm-base-plus\n",
      "    nlayers: 13\n",
      "    sr: 16000\n",
      "  style_dim: 128\n",
      "optimizer_params:\n",
      "  lr: 0.0001\n",
      "preprocess_params:\n",
      "  spect_params:\n",
      "    hop_length: 300\n",
      "    n_fft: 2048\n",
      "    n_mels: 80\n",
      "    win_length: 1200\n",
      "  sr: 24000\n",
      "pretrained_model: Models/LibriTTS/epochs_2nd_00020.pth\n",
      "save_freq: 10\n",
      "slmadv_params:\n",
      "  batch_percentage: 0.5\n",
      "  iter: 10\n",
      "  max_len: 500\n",
      "  min_len: 400\n",
      "  scale: 0.01\n",
      "  sig: 1.5\n",
      "  thresh: 5.0\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-3JszuhM0tM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764266006256,
     "user_tz": -60,
     "elapsed": 18376,
     "user": {
      "displayName": "Racim Si Smail",
      "userId": "13880419371013186198"
     }
    },
    "outputId": "065b489b-cfca-48ab-fb42-b804b3503dbd"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/StyleTTS2\n",
      "2025-11-27 17:53:13.246499: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764265993.267122   19374 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764265993.273407   19374 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764265993.289185   19374 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764265993.289210   19374 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764265993.289213   19374 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764265993.289215   19374 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-27 17:53:13.293965: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/StyleTTS2/train_finetune.py\", line 707, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1485, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1406, in main\n",
      "    rv = self.invoke(ctx)\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1269, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 824, in invoke\n",
      "    return callback(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/StyleTTS2/train_finetune.py\", line 158, in main\n",
      "    raise ValueError('You need to specify the path to the first stage model.') \n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: You need to specify the path to the first stage model.\n"
     ]
    }
   ],
   "source": [
    "%cd /content/StyleTTS2\n",
    "!python train_finetune.py --config_path ./Configs/config_darija_a100.yml 2>&1 | tail -50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOqC8cNWM0tM"
   },
   "source": [
    "## 10. Sauvegarde sur Google Drive (IMPORTANT!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6FWHVL0M0tM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764263007648,
     "user_tz": -60,
     "elapsed": 36077,
     "user": {
      "displayName": "Racim Si Smail",
      "userId": "13880419371013186198"
     }
    },
    "outputId": "12c167ee-72f3-4cb9-bf6e-8a9f32730fa4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "\ud83d\udcbe Sauvegarde des checkpoints sur Google Drive...\n",
      "\u2705 train.log\n",
      "\u2705 config_darija_ft.yml\n",
      "\n",
      "\ud83c\udf89 Checkpoints sauvegard\u00e9s sur Drive!\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Monter Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Cr\u00e9er le dossier de sauvegarde\n",
    "backup_dir = '/content/drive/MyDrive/darija_checkpoints'\n",
    "os.makedirs(backup_dir, exist_ok=True)\n",
    "\n",
    "# Copier les checkpoints\n",
    "print(\"\ud83d\udcbe Sauvegarde des checkpoints sur Google Drive...\")\n",
    "source_dir = '/content/StyleTTS2/Models/Darija'\n",
    "if os.path.exists(source_dir):\n",
    "    for item in os.listdir(source_dir):\n",
    "        source_path = os.path.join(source_dir, item)\n",
    "        dest_path = os.path.join(backup_dir, item)\n",
    "        if os.path.isfile(source_path):\n",
    "            shutil.copy2(source_path, dest_path)\n",
    "            print(f\"\u2705 {item}\")\n",
    "    print(\"\\n\ud83c\udf89 Checkpoints sauvegard\u00e9s sur Drive!\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f Aucun checkpoint trouv\u00e9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNt5U3g1M0tN"
   },
   "source": [
    "## 11. Upload du mod\u00e8le entra\u00een\u00e9 sur Hugging Face (optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PlRtbEXKM0tN"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, login\n",
    "\n",
    "# Configuration\n",
    "HF_MODEL_REPO = \"VOTRE-USERNAME/darija-styletts2\"  # Changez ici\n",
    "HF_TOKEN_UPLOAD = \"\"  # Votre token HF avec droits write\n",
    "\n",
    "if HF_TOKEN_UPLOAD:\n",
    "    print(\"\ud83d\udd10 Connexion \u00e0 Hugging Face...\")\n",
    "    login(token=HF_TOKEN_UPLOAD)\n",
    "\n",
    "    api = HfApi()\n",
    "\n",
    "    # Cr\u00e9er le repo\n",
    "    api.create_repo(repo_id=HF_MODEL_REPO, repo_type=\"model\", exist_ok=True)\n",
    "\n",
    "    # Upload les checkpoints\n",
    "    print(f\"\ud83d\udce4 Upload vers {HF_MODEL_REPO}...\")\n",
    "    api.upload_folder(\n",
    "        folder_path=\"/content/StyleTTS2/Models/Darija\",\n",
    "        repo_id=HF_MODEL_REPO,\n",
    "        repo_type=\"model\"\n",
    "    )\n",
    "\n",
    "    print(f\"\u2705 Mod\u00e8le disponible sur: https://huggingface.co/{HF_MODEL_REPO}\")\n",
    "else:\n",
    "    print(\"\u2139\ufe0f Token HF non fourni, upload ignor\u00e9\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}