{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé§ Fine-Tuning StyleTTS2 pour le Darija\n",
        "\n",
        "## Version Optimis√©e GitHub + HuggingFace (Setup rapide ~3 min)\n",
        "\n",
        "**Sources:**\n",
        "- üì¶ **Code:** `github.com/VOTRE-USERNAME/arable-tts` ‚¨ÖÔ∏è Remplacez par votre username GitHub\n",
        "- üéµ **Audio:** `huggingface.co/datasets/VOTRE-USERNAME/darija-dataset` ‚¨ÖÔ∏è Remplacez par votre repo HF\n",
        "\n",
        "### Pr√©requis:\n",
        "- GPU: T4, V100, ou A100 (minimum 16GB VRAM)\n",
        "- Dataset d√©j√† upload√© sur Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Configuration - MODIFIEZ ICI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß CONFIGURATION - Modifiez ces valeurs\n",
        "GITHUB_REPO = \"VOTRE-USERNAME/arable-tts\"  # Votre repo GitHub\n",
        "HF_DATASET_REPO = \"VOTRE-USERNAME/darija-dataset\"  # Votre dataset HuggingFace\n",
        "HF_TOKEN = \"\"  # Optionnel, seulement si dataset priv√©\n",
        "\n",
        "print(f\"‚úÖ GitHub: {GITHUB_REPO}\")\n",
        "print(f\"‚úÖ HuggingFace: {HF_DATASET_REPO}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. V√©rification GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "import torch\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Installation des d√©pendances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q phonemizer==3.2.1 munch accelerate pydub nltk g2p_en num2words inflect unidecode pyyaml librosa scipy matplotlib soundfile\n",
        "!pip install -q torch torchaudio transformers einops einops-exts tqdm omegaconf huggingface_hub\n",
        "!pip install -q git+https://github.com/resemble-ai/monotonic_align.git\n",
        "!apt-get install -qq espeak-ng\n",
        "print(\"‚úÖ D√©pendances install√©es!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. T√©l√©chargement du code (GitHub) et audio (HuggingFace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "# Cloner StyleTTS2\n",
        "if not os.path.exists(\"/content/StyleTTS2\"):\n",
        "    !git clone https://github.com/yl4579/StyleTTS2.git /content/StyleTTS2\n",
        "    print(\"‚úÖ StyleTTS2 clon√©!\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è StyleTTS2 d√©j√† pr√©sent\")\n",
        "\n",
        "# Cloner votre repo avec les configs\n",
        "if not os.path.exists(\"/content/arable-tts\"):\n",
        "    !git clone https://github.com/{GITHUB_REPO}.git /content/arable-tts\n",
        "    print(\"‚úÖ Configs clon√©es depuis GitHub!\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Repo d√©j√† pr√©sent\")\n",
        "\n",
        "# T√©l√©charger les audio depuis HuggingFace\n",
        "print(f\"üì• T√©l√©chargement audio depuis HuggingFace: {HF_DATASET_REPO}...\")\n",
        "snapshot_download(\n",
        "    repo_id=HF_DATASET_REPO,\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=\"/content/dataset_darija\",\n",
        "    local_dir_use_symlinks=False,\n",
        "    token=HF_TOKEN if HF_TOKEN else None\n",
        ")\n",
        "print(\"‚úÖ Dataset audio t√©l√©charg√©!\")\n",
        "\n",
        "# V√©rifier ce qui a √©t√© t√©l√©charg√©\n",
        "if os.path.exists(\"/content/dataset_darija/wavs\"):\n",
        "    wav_count = len([f for f in os.listdir(\"/content/dataset_darija/wavs\") if f.endswith('.wav')])\n",
        "    print(f\"üéµ {wav_count} fichiers audio d√©tect√©s\")\n",
        "\n",
        "metadata_files = [\"metadata_train.csv\", \"metadata_eval.csv\", \"metadata.json\"]\n",
        "for mf in metadata_files:\n",
        "    if os.path.exists(f\"/content/dataset_darija/{mf}\"):\n",
        "        print(f\"üìÑ {mf} pr√©sent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. T√©l√©chargement des mod√®les pr√©-entra√Æn√©s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p /content/StyleTTS2/Models/LibriTTS /content/StyleTTS2/Models/Darija\n",
        "!mkdir -p /content/StyleTTS2/Utils/JDC /content/StyleTTS2/Utils/ASR /content/StyleTTS2/Utils/PLBERT\n",
        "\n",
        "print(\"üì• T√©l√©chargement des mod√®les pr√©-entra√Æn√©s...\")\n",
        "\n",
        "# Mod√®le principal\n",
        "!wget -q --show-progress -O /content/StyleTTS2/Models/LibriTTS/epochs_2nd_00020.pth \\\n",
        "    https://huggingface.co/yl4579/StyleTTS2-LibriTTS/resolve/main/Models/LibriTTS/epochs_2nd_00020.pth\n",
        "!wget -q -O /content/StyleTTS2/Models/LibriTTS/config.yml \\\n",
        "    https://huggingface.co/yl4579/StyleTTS2-LibriTTS/resolve/main/Models/LibriTTS/config.yml\n",
        "\n",
        "# JDC (pitch extractor)\n",
        "!wget -q --show-progress -O /content/StyleTTS2/Utils/JDC/bst.t7 \\\n",
        "    https://huggingface.co/yl4579/StyleTTS2-LibriTTS/resolve/main/Utils/JDC/bst.t7\n",
        "\n",
        "# ASR (speech recognition)\n",
        "!wget -q --show-progress -O /content/StyleTTS2/Utils/ASR/epoch_00080.pth \\\n",
        "    https://huggingface.co/yl4579/StyleTTS2-LibriTTS/resolve/main/Utils/ASR/epoch_00080.pth\n",
        "!wget -q -O /content/StyleTTS2/Utils/ASR/config.yml \\\n",
        "    https://huggingface.co/yl4579/StyleTTS2-LibriTTS/resolve/main/Utils/ASR/config.yml\n",
        "\n",
        "# PLBERT (phoneme encoder)\n",
        "!wget -q --show-progress -O /content/StyleTTS2/Utils/PLBERT/step_1000000.t7 \\\n",
        "    https://huggingface.co/yl4579/StyleTTS2-LibriTTS/resolve/main/Utils/PLBERT/step_1000000.t7\n",
        "!wget -q -O /content/StyleTTS2/Utils/PLBERT/config.yml \\\n",
        "    https://huggingface.co/yl4579/StyleTTS2-LibriTTS/resolve/main/Utils/PLBERT/config.yml\n",
        "\n",
        "print(\"‚úÖ Mod√®les pr√©-entra√Æn√©s t√©l√©charg√©s!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Patches PyTorch 2.6+ (CRITIQUE!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re, os\n",
        "\n",
        "files_to_patch = [\n",
        "    \"/content/StyleTTS2/models.py\",\n",
        "    \"/content/StyleTTS2/Utils/ASR/models.py\",\n",
        "    \"/content/StyleTTS2/Utils/JDC/model.py\",\n",
        "    \"/content/StyleTTS2/Utils/PLBERT/util.py\",\n",
        "    \"/content/StyleTTS2/meldataset.py\",\n",
        "]\n",
        "\n",
        "for filepath in files_to_patch:\n",
        "    if os.path.exists(filepath):\n",
        "        with open(filepath, 'r') as f:\n",
        "            content = f.read()\n",
        "        if 'torch.load' in content and 'weights_only' not in content:\n",
        "            new_content = re.sub(r'torch\\.load\\(([^)]+)\\)', r'torch.load(\\1, weights_only=False)', content)\n",
        "            with open(filepath, 'w') as f:\n",
        "                f.write(new_content)\n",
        "            print(f\"‚úÖ Patched: {os.path.basename(filepath)}\")\n",
        "        else:\n",
        "            print(f\"‚ÑπÔ∏è OK: {os.path.basename(filepath)}\")\n",
        "\n",
        "print(\"\\n‚úÖ Patches PyTorch appliqu√©s!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Pr√©paration des donn√©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json, random, os, shutil\n",
        "\n",
        "os.makedirs(\"/content/StyleTTS2/Data\", exist_ok=True)\n",
        "os.makedirs(\"/content/StyleTTS2/wavs\", exist_ok=True)\n",
        "\n",
        "# Copier les fichiers audio\n",
        "print(\"üéµ Copie des fichiers audio...\")\n",
        "source_wavs = \"/content/dataset_darija/wavs\"\n",
        "dest_wavs = \"/content/StyleTTS2/wavs\"\n",
        "\n",
        "if os.path.exists(source_wavs):\n",
        "    for f in os.listdir(source_wavs):\n",
        "        if f.endswith('.wav'):\n",
        "            shutil.copy(f\"{source_wavs}/{f}\", f\"{dest_wavs}/{f}\")\n",
        "    print(f\"‚úÖ {len(os.listdir(dest_wavs))} fichiers audio copi√©s\")\n",
        "else:\n",
        "    print(\"‚ùå Dossier wavs introuvable!\")\n",
        "\n",
        "# Cr√©er train/val lists depuis metadata.json\n",
        "metadata_path = \"/content/dataset_darija/metadata.json\"\n",
        "if os.path.exists(metadata_path):\n",
        "    with open(metadata_path, 'r', encoding='utf-8') as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "    random.seed(42)\n",
        "    random.shuffle(metadata)\n",
        "    split = int(len(metadata) * 0.95)\n",
        "    train_data, eval_data = metadata[:split], metadata[split:]\n",
        "\n",
        "    with open('/content/StyleTTS2/Data/train_list.txt', 'w', encoding='utf-8') as f:\n",
        "        for item in train_data:\n",
        "            f.write(f\"{item['audio_file']}|{item['text'].replace(chr(10), ' ')}|0\\n\")\n",
        "\n",
        "    with open('/content/StyleTTS2/Data/val_list.txt', 'w', encoding='utf-8') as f:\n",
        "        for item in eval_data:\n",
        "            f.write(f\"{item['audio_file']}|{item['text'].replace(chr(10), ' ')}|0\\n\")\n",
        "\n",
        "    print(f\"‚úÖ Train: {len(train_data)} samples\")\n",
        "    print(f\"‚úÖ Val: {len(eval_data)} samples\")\n",
        "else:\n",
        "    print(\"‚ùå metadata.json introuvable!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Configuration du training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml, os\n",
        "\n",
        "config = {\n",
        "    'log_dir': 'Models/Darija',\n",
        "    'save_freq': 10,\n",
        "    'device': 'cuda',\n",
        "    'epochs_1st': 0,\n",
        "    'epochs_2nd': 80,\n",
        "    'batch_size': 4,\n",
        "    'max_len': 400,\n",
        "    'pretrained_model': 'Models/LibriTTS/epochs_2nd_00020.pth',\n",
        "    'data_params': {\n",
        "        'train_data': 'Data/train_list.txt',\n",
        "        'val_data': 'Data/val_list.txt',\n",
        "        'root_path': '',\n",
        "        'OOD_data': 'Data/OOD_texts.txt',\n",
        "        'min_length': 50,\n",
        "        'sample_rate': 24000,\n",
        "    },\n",
        "    'preprocess_params': {\n",
        "        'sr': 24000,\n",
        "        'spect_params': {\n",
        "            'n_fft': 2048,\n",
        "            'win_length': 1200,\n",
        "            'hop_length': 300,\n",
        "            'n_mels': 80\n",
        "        }\n",
        "    },\n",
        "    'model_params': {\n",
        "        'multispeaker': False,\n",
        "        'dim_in': 64,\n",
        "        'hidden_dim': 512,\n",
        "        'max_conv_dim': 512,\n",
        "        'n_layer': 3,\n",
        "        'n_mels': 80,\n",
        "        'n_token': 178,\n",
        "        'max_dur': 50,\n",
        "        'style_dim': 128,\n",
        "        'dropout': 0.2,\n",
        "        'decoder': {\n",
        "            'type': 'istftnet',\n",
        "            'resblock_kernel_sizes': [3, 7, 11],\n",
        "            'upsample_rates': [10, 6],\n",
        "            'upsample_initial_channel': 512,\n",
        "            'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]],\n",
        "            'upsample_kernel_sizes': [20, 12],\n",
        "            'gen_istft_n_fft': 20,\n",
        "            'gen_istft_hop_size': 5\n",
        "        },\n",
        "        'slm': {\n",
        "            'model': 'microsoft/wavlm-base-plus',\n",
        "            'sr': 16000,\n",
        "            'hidden': 768,\n",
        "            'nlayers': 13,\n",
        "            'initial_channel': 64\n",
        "        },\n",
        "        'diffusion': {\n",
        "            'embedding_mask_proba': 0.1,\n",
        "            'transformer': {\n",
        "                'num_layers': 3,\n",
        "                'num_heads': 8,\n",
        "                'head_features': 64,\n",
        "                'multiplier': 2\n",
        "            },\n",
        "            'dist': {\n",
        "                'sigma_data': 0.2,\n",
        "                'estimate_sigma_data': True,\n",
        "                'mean': -3.0,\n",
        "                'std': 1.0\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    'loss_params': {\n",
        "        'lambda_mel': 5.0,\n",
        "        'lambda_gen': 1.0,\n",
        "        'lambda_slm': 1.0,\n",
        "        'lambda_mono': 1.0,\n",
        "        'lambda_s2s': 1.0,\n",
        "        'lambda_F0': 1.0,\n",
        "        'lambda_norm': 1.0,\n",
        "        'lambda_dur': 1.0,\n",
        "        'lambda_ce': 20.0,\n",
        "        'lambda_sty': 1.0,\n",
        "        'lambda_diff': 1.0,\n",
        "        'diff_epoch': 20,\n",
        "        'joint_epoch': 40\n",
        "    },\n",
        "    'optimizer_params': {'lr': 0.0001},\n",
        "    'slmadv_params': {\n",
        "        'min_len': 400,\n",
        "        'max_len': 500,\n",
        "        'batch_percentage': 0.5,\n",
        "        'iter': 10,\n",
        "        'thresh': 5.0,\n",
        "        'scale': 0.01,\n",
        "        'sig': 1.5\n",
        "    },\n",
        "    'F0_path': 'Utils/JDC/bst.t7',\n",
        "    'ASR_config': 'Utils/ASR/config.yml',\n",
        "    'ASR_path': 'Utils/ASR/epoch_00080.pth',\n",
        "    'PLBERT_dir': 'Utils/PLBERT/',\n",
        "}\n",
        "\n",
        "os.makedirs('/content/StyleTTS2/Configs', exist_ok=True)\n",
        "with open('/content/StyleTTS2/Configs/config_darija_ft.yml', 'w') as f:\n",
        "    yaml.dump(config, f)\n",
        "\n",
        "print(\"‚úÖ Configuration cr√©√©e!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. V√©rification finale avant training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "checks = {\n",
        "    \"Config\": \"/content/StyleTTS2/Configs/config_darija_ft.yml\",\n",
        "    \"Audio (wavs)\": \"/content/StyleTTS2/wavs\",\n",
        "    \"Train list\": \"/content/StyleTTS2/Data/train_list.txt\",\n",
        "    \"Val list\": \"/content/StyleTTS2/Data/val_list.txt\",\n",
        "    \"Mod√®le LibriTTS\": \"/content/StyleTTS2/Models/LibriTTS/epochs_2nd_00020.pth\",\n",
        "    \"JDC\": \"/content/StyleTTS2/Utils/JDC/bst.t7\",\n",
        "    \"ASR\": \"/content/StyleTTS2/Utils/ASR/epoch_00080.pth\",\n",
        "    \"PLBERT\": \"/content/StyleTTS2/Utils/PLBERT/step_1000000.t7\",\n",
        "}\n",
        "\n",
        "all_ok = True\n",
        "for name, path in checks.items():\n",
        "    exists = os.path.exists(path)\n",
        "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
        "    print(f\"{status} {name}\")\n",
        "    if not exists:\n",
        "        all_ok = False\n",
        "\n",
        "# Compter les fichiers\n",
        "if os.path.exists(\"/content/StyleTTS2/wavs\"):\n",
        "    wav_count = len([f for f in os.listdir(\"/content/StyleTTS2/wavs\") if f.endswith('.wav')])\n",
        "    print(f\"\\nüéµ {wav_count} fichiers audio pr√™ts\")\n",
        "\n",
        "if all_ok:\n",
        "    print(\"\\nüéâ TOUT EST PR√äT! Vous pouvez lancer le training!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Certains fichiers manquent. V√©rifiez les √©tapes pr√©c√©dentes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. üöÄ Lancement du Fine-Tuning\n",
        "\n",
        "‚ö†Ô∏è **Dur√©e estim√©e: 8-12h sur GPU T4**\n",
        "\n",
        "Checkpoints sauvegard√©s tous les 10 epochs dans `/content/StyleTTS2/Models/Darija/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/StyleTTS2\n",
        "!accelerate launch --mixed_precision=no --num_processes=1 train_finetune.py --config_path ./Configs/config_darija_ft.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Sauvegarde sur Google Drive (IMPORTANT!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Monter Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Cr√©er le dossier de sauvegarde\n",
        "backup_dir = '/content/drive/MyDrive/darija_checkpoints'\n",
        "os.makedirs(backup_dir, exist_ok=True)\n",
        "\n",
        "# Copier les checkpoints\n",
        "print(\"üíæ Sauvegarde des checkpoints sur Google Drive...\")\n",
        "source_dir = '/content/StyleTTS2/Models/Darija'\n",
        "if os.path.exists(source_dir):\n",
        "    for item in os.listdir(source_dir):\n",
        "        source_path = os.path.join(source_dir, item)\n",
        "        dest_path = os.path.join(backup_dir, item)\n",
        "        if os.path.isfile(source_path):\n",
        "            shutil.copy2(source_path, dest_path)\n",
        "            print(f\"‚úÖ {item}\")\n",
        "    print(\"\\nüéâ Checkpoints sauvegard√©s sur Drive!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Aucun checkpoint trouv√©\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Upload du mod√®le entra√Æn√© sur Hugging Face (optionnel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi, login\n",
        "\n",
        "# Configuration\n",
        "HF_MODEL_REPO = \"VOTRE-USERNAME/darija-styletts2\"  # Changez ici\n",
        "HF_TOKEN_UPLOAD = \"\"  # Votre token HF avec droits write\n",
        "\n",
        "if HF_TOKEN_UPLOAD:\n",
        "    print(\"üîê Connexion √† Hugging Face...\")\n",
        "    login(token=HF_TOKEN_UPLOAD)\n",
        "    \n",
        "    api = HfApi()\n",
        "    \n",
        "    # Cr√©er le repo\n",
        "    api.create_repo(repo_id=HF_MODEL_REPO, repo_type=\"model\", exist_ok=True)\n",
        "    \n",
        "    # Upload les checkpoints\n",
        "    print(f\"üì§ Upload vers {HF_MODEL_REPO}...\")\n",
        "    api.upload_folder(\n",
        "        folder_path=\"/content/StyleTTS2/Models/Darija\",\n",
        "        repo_id=HF_MODEL_REPO,\n",
        "        repo_type=\"model\"\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Mod√®le disponible sur: https://huggingface.co/{HF_MODEL_REPO}\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Token HF non fourni, upload ignor√©\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
