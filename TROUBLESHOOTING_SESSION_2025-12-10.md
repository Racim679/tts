# Session de Troubleshooting - Fine-tuning StyleTTS2 Darija
**Date**: 2025-12-10
**DurÃ©e**: ~3 heures
**Statut Final**: âœ… PrÃªt pour training sur A100

---

## ğŸ“‹ RÃ©sumÃ© de la Session

### ProblÃ¨mes RÃ©solus

1. **Erreur `weights_only` dans PyTorch 2.6+**
   - **Cause**: PyTorch 2.6+ nÃ©cessite `weights_only=False` pour `torch.load()`
   - **Fichiers corrigÃ©s**:
     - `Utils/PLBERT/util.py:30`
     - `models.py` (plusieurs occurrences)
   - **Solution**: Ajout de `weights_only=False` Ã  tous les `torch.load()`

2. **Erreur `ValueError: first stage model`**
   - **Cause**: Config manquait `second_stage_load_pretrained: true`
   - **Solution**: Config complÃ¨te uploadÃ©e sur GitHub

3. **Erreur `soundfile.LibsndfileError`**
   - **Cause**: Metadata.json contenait des UUIDs au lieu des transcriptions
   - **Solution**: GÃ©nÃ©ration de `metadata_correct.json` depuis le CSV Gemini (1509 â†’ 1052 entrÃ©es valides)

4. **Erreur `TypeError: ASRCNN got dim_in`**
   - **Cause**: Config ASR corrompue avec `dim_in` au lieu de `input_dim`
   - **Solution**: RÃ©gÃ©nÃ©ration complÃ¨te de `Utils/ASR/config.yml`

5. **Erreur `CUDA out of memory` sur T4**
   - **Cause**: ModÃ¨le trop lourd pour 15GB VRAM (T4)
   - **Solution**: Migration vers A100 (80GB) ou rÃ©duction `batch_size=2, max_len=200`

---

## ğŸ“‚ Fichiers ClÃ©s CrÃ©Ã©s/ModifiÃ©s

### Sur GitHub (`Racim679/tts`)

```
StyleTTS2/
â”œâ”€â”€ Configs/
â”‚   â””â”€â”€ config_darija_ft.yml         âœ… Config correcte (hifigan decoder, second_stage=true)
â”œâ”€â”€ Utils/
â”‚   â”œâ”€â”€ ASR/config.yml               âœ… input_dim=80, token_embedding_dim=512
â”‚   â””â”€â”€ PLBERT/util.py               âœ… PatchÃ© weights_only=False
â”œâ”€â”€ models.py                         âœ… PatchÃ© weights_only=False
â”œâ”€â”€ train_finetune.py                 âœ… num_workers=0, debug prints
â””â”€â”€ .gitignore                        âœ… Exclut .pth et .wav

metadata_correct.json                 âœ… 1509 transcriptions Darija (filtrÃ© Ã  1052)
```

### En Local (non commitÃ©)

```
C:\Users\Racim\Desktop\arable tts - Copie/
â”œâ”€â”€ gemini_audio_transcription_rows (1).csv  ğŸ“„ Source des transcriptions
â”œâ”€â”€ fix_metadata_noemoji.py                   ğŸ”§ Script de gÃ©nÃ©ration metadata
â””â”€â”€ metadata_correct.json                     âœ… 1509 entrÃ©es originales
```

---

## âš™ï¸ Configuration Finale

### Pour A100 (80GB VRAM)

```yaml
# Configs/config_darija_ft.yml
batch_size: 16
max_len: 400
pretrained_model: Models/LibriTTS/epochs_2nd_00020.pth
second_stage_load_pretrained: true
load_only_params: true

model_params:
  decoder:
    type: hifigan  # âš ï¸ CRITIQUE (pas istftnet)

data_params:
  root_path: /content/StyleTTS2
  train_data: Data/train_list.txt
  val_data: Data/val_list.txt
```

### Pour T4 (15GB VRAM) - Alternative

```yaml
batch_size: 2
max_len: 200
slmadv_params:
  min_len: 150
  max_len: 250
```

---

## ğŸ—‚ï¸ Dataset

### Structure du Metadata Correct

```json
{
  "audio_file": "wavs/audio_107_seg057.wav",
  "text": "Ù„ÙˆØ¬ÙˆÙ† Ù„ÙŠ Ù‡Ù†Ø§ ÙÙŠ Ø§Ù„Ù‚Ø¨Ù‡ Ø¨Ø³ÙˆÙ…Ù‡ 8 Ù…Ù„Ø§ÙŠØ± Ùˆ200...",
  "speaker_id": "692"
}
```

### Statistiques

- **Total fichiers audio**: 1052 `.wav`
- **Total transcriptions valides**: 1052 (filtrÃ© depuis 1509)
- **Train samples**: 999
- **Val samples**: 53
- **Sample rate**: 48kHz (Ã  resampler Ã  24kHz par StyleTTS2)

---

## ğŸš€ Cellules Colab Finales

### 1. Setup Initial

```python
# Installation dÃ©pendances
!pip install -q phonemizer==3.2.1 munch accelerate transformers einops tqdm
!pip install -q git+https://github.com/resemble-ai/monotonic_align.git
!apt-get install -qq espeak-ng
```

### 2. TÃ©lÃ©chargement Code + ModÃ¨les

```python
# Cloner StyleTTS2 original
!git clone https://github.com/yl4579/StyleTTS2.git /content/StyleTTS2

# TÃ©lÃ©charger checkpoints prÃ©-entraÃ®nÃ©s
!mkdir -p /content/StyleTTS2/Models/LibriTTS
!wget -O /content/StyleTTS2/Models/LibriTTS/epochs_2nd_00020.pth \
    https://huggingface.co/yl4579/StyleTTS2-LibriTTS/resolve/main/epochs_2nd_00020.pth

# TÃ©lÃ©charger Utils (ASR, PLBERT, JDC)
!wget -O /content/StyleTTS2/Utils/ASR/epoch_00080.pth \
    https://github.com/yl4579/StyleTTS2/raw/main/Utils/ASR/epoch_00080.pth
# ... (voir notebook complet)
```

### 3. Correction Metadata + Config

```python
# TÃ©lÃ©charger metadata correct depuis GitHub
import requests
url = "https://raw.githubusercontent.com/Racim679/tts/main/metadata_correct.json"
metadata = requests.get(url).json()

# Filtrer pour fichiers existants
# GÃ©nÃ©rer train_list.txt et val_list.txt
# (voir code complet dans TROUBLESHOOTING)
```

### 4. RÃ©initialisation Config

```python
# TÃ©lÃ©charger config correcte depuis GitHub
config_url = "https://raw.githubusercontent.com/Racim679/tts/main/StyleTTS2/Configs/config_darija_ft.yml"
config = yaml.safe_load(requests.get(config_url).text)

# Ajuster pour A100
config['batch_size'] = 16
config['data_params']['root_path'] = '/content/StyleTTS2'

# Sauvegarder
with open('/content/StyleTTS2/Configs/config_darija_ft.yml', 'w') as f:
    yaml.dump(config, f)
```

### 5. Lancement Training

```python
%cd /content/StyleTTS2
!python train_finetune.py --config_path Configs/config_darija_ft.yml
```

---

## ğŸ› Erreurs Communes & Solutions

| Erreur | Cause | Solution |
|--------|-------|----------|
| `weights_only is invalid keyword` | Syntaxe PyTorch incorrecte | `str(iters, weights_only=False)` â†’ `str(iters)` + `weights_only=False` dans `torch.load()` |
| `ValueError: first stage model` | `second_stage_load_pretrained` manquant | Ajouter `second_stage_load_pretrained: true` |
| `soundfile.LibsndfileError` | Textes sont des UUIDs | Utiliser `metadata_correct.json` |
| `TypeError: ASRCNN got dim_in` | Config ASR corrompue | Utiliser `input_dim` au lieu de `dim_in` |
| `CUDA out of memory` | Batch trop gros pour GPU | RÃ©duire `batch_size` et `max_len` |
| `decoder type: istftnet` | Mauvaise config | Forcer `decoder.type: hifigan` |

---

## ğŸ“Š Performance Attendue

### Avec A100

- **DurÃ©e totale**: 6-8 heures (80 epochs)
- **Batch size**: 16
- **Samples/sec**: ~50-60
- **Checkpoints**: SauvegardÃ©s tous les 10 epochs

### Avec T4 (fallback)

- **DurÃ©e totale**: 24-30 heures (80 epochs)
- **Batch size**: 2
- **Samples/sec**: ~10-15

---

## ğŸ”„ Workflow Git

### Commits Principaux

```bash
6290915  Add StyleTTS2 with Darija config and PyTorch 2.6 patches
efd92d6  Add correct metadata.json with real Darija transcriptions (1509 samples)
```

### Structure GitHub

```
https://github.com/Racim679/tts/
â”œâ”€â”€ StyleTTS2/          # Code StyleTTS2 modifiÃ©
â”œâ”€â”€ metadata_correct.json  # Transcriptions valides
â””â”€â”€ dataset_training/   # (local uniquement, exclu par .gitignore)
```

---

## ğŸ“ Notes Importantes

1. **Checkpoints prÃ©-entraÃ®nÃ©s**: Ne JAMAIS commit les `.pth` (735MB) sur GitHub
2. **Audio files**: HÃ©bergÃ©s sur HuggingFace: `RacimPoly6/darija-tts-dataset`
3. **Transcriptions source**: CSV Supabase `gemini_audio_transcription_rows (1).csv`
4. **Encoder UTF-8**: Toujours utiliser `encoding='utf-8'` pour les fichiers arabes
5. **Windows CP1252**: Ã‰viter les emojis dans les scripts Python locaux

---

## ğŸ¯ Prochaines Ã‰tapes

1. âœ… **Lancer le training sur A100** avec la config finale
2. â³ **Surveiller TensorBoard** pour loss convergence
3. ğŸ’¾ **Sauvegarder checkpoints** sur Google Drive tous les 10 epochs
4. ğŸ§ª **Tester infÃ©rence** avec `epoch_2nd_00050.pth` (aprÃ¨s ~4h)
5. ğŸ“¤ **Upload modÃ¨le final** sur HuggingFace aprÃ¨s training complet

---

## ğŸ”— Ressources

- **Repo GitHub**: https://github.com/Racim679/tts
- **Dataset HuggingFace**: https://huggingface.co/datasets/RacimPoly6/darija-tts-dataset
- **StyleTTS2 Original**: https://github.com/yl4579/StyleTTS2
- **Checkpoint LibriTTS**: https://huggingface.co/yl4579/StyleTTS2-LibriTTS

---

## ğŸ†˜ Support

Si problÃ¨mes lors du prochain training :

1. **VÃ©rifier les configs** :
   ```python
   # Config principale
   second_stage_load_pretrained: true  # âš ï¸ CRITIQUE
   decoder.type: hifigan                # âš ï¸ CRITIQUE

   # Config ASR
   input_dim: 80                        # âš ï¸ PAS dim_in !
   token_embedding_dim: 512             # âš ï¸ CRITIQUE
   ```

2. **Nettoyer mÃ©moire GPU** :
   ```python
   torch.cuda.empty_cache()
   gc.collect()
   ```

3. **Restaurer config depuis GitHub** :
   ```bash
   wget https://raw.githubusercontent.com/Racim679/tts/main/StyleTTS2/Configs/config_darija_ft.yml
   ```

---

**GÃ©nÃ©rÃ© le**: 2025-12-10
**DerniÃ¨re mise Ã  jour**: 2025-12-10 18:30 UTC
**Statut**: âœ… PrÃªt pour production sur A100
